# ğŸ¤– Chatbot RAG com Elasticsearch + FastAPI

Este projeto entrega um **chatbot corporativo** simples, baseado em **Elasticsearch** para recuperaÃ§Ã£o de contexto (BM25) e **FastAPI** como orquestrador.  
Ele foi desenhado para ser **fÃ¡cil de subir** com Docker Compose e extensÃ­vel com LLMs como **OpenAI** ou **Ollama**.  

---

## ğŸ“ Arquitetura

```
[UsuÃ¡rio via UI ou API] ---> [/api/ask] FastAPI ---> Elasticsearch (BM25)
                                   | 
                                   +--> (Opcional) LLM (OpenAI/Ollama)
                                   |
                               Resposta final + fontes
```

- **Elasticsearch**: indexa os documentos em Markdown.  
- **FastAPI**: recebe perguntas, busca os docs relevantes, monta prompt e (opcional) envia para LLM.  
- **UI Web**: pÃ¡gina simples em `/static/index.html`.  
- **Telemetria**: cada interaÃ§Ã£o Ã© logada em `chat_logs` no Elasticsearch.  

---

## ğŸš€ Como rodar

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/sua-org/elastic-chatbot.git
cd elastic-chatbot
```

### 2. Configure o `.env`
```bash
cp retriever-api/.env.example retriever-api/.env
```

OpÃ§Ãµes de LLM:
- `none` â†’ responde sÃ³ com os trechos recuperados.
- `openai:gpt-4o-mini` â†’ usa OpenAI (precisa `OPENAI_API_KEY`).
- `ollama:llama3.1` â†’ usa Ollama local.

### 3. Suba os containers
```bash
docker compose up -d --build
```

### 4. IngestÃ£o de documentos
Coloque arquivos `.md` em `retriever-api/docs/` (jÃ¡ existem alguns exemplos).  
Depois, rode:

```bash
docker compose exec retriever-api python -m scripts.ingest
```

---

## ğŸ’¬ Exemplos de uso

### API
```bash
curl -s http://localhost:8000/api/ask -H "Content-Type: application/json" -d '{
  "question": "Como estÃ¡ estruturado nosso CI/CD?",
  "k": 3
}'
```

### UI
Abra no navegador:  
ğŸ‘‰ [http://localhost:8000/](http://localhost:8000/)  

### Swagger
ğŸ‘‰ [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“Š Observabilidade e Uso

Toda pergunta/resposta Ã© logada no Ã­ndice `chat_logs`.  
VocÃª pode explorar via API:

```bash
curl -s http://localhost:8000/usage
```

Ou criar um **Dashboard no Kibana**:
- **Chats ao longo do tempo**  
- **MÃ©dia do tamanho da resposta**  
- **TÃ³picos mais perguntados**  
- **% de perguntas com contexto**  

---

## ğŸ“‚ Estrutura do projeto

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ retriever-api/
â”‚   â”œâ”€â”€ app.py                 # API principal
â”‚   â”œâ”€â”€ elastic_client.py      # Cliente ES
â”‚   â”œâ”€â”€ llm_client.py          # OpenAI/Ollama/none
â”‚   â”œâ”€â”€ prompt.py              # Template de prompt
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ ingest.py          # IngestÃ£o de docs
â”‚   â”‚   â””â”€â”€ sample_index_settings.json
â”‚   â”œâ”€â”€ docs/                  # Documentos a indexar
â”‚   â”œâ”€â”€ static/                # UI web simples
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env.example
â””â”€â”€ extras/
    â””â”€â”€ langflow/flow.json     # Flow opcional no Langflow
```

---

## ğŸ› ï¸ PrÃ³ximos passos

- [ ] Adicionar suporte a embeddings (kNN).  
- [ ] Implementar busca hÃ­brida (BM25 + vetores).  
- [ ] Re-ranking com Cross-Encoder ou LLM leve.  
- [ ] Upload de PDFs/HTML com parsing automÃ¡tico.  
- [ ] Dashboard Kibana pronto para uso.  

---

## ğŸ“œ LicenÃ§a
MIT â€” livre para uso e adaptaÃ§Ã£o.  
